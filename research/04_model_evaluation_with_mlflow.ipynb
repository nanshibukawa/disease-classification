{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ffc24d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd20d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nanshibukawa/Documents/mestrado/disease-classification/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8deb96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de49f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nanshibukawa/Documents/mestrado/disease-classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bc7d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/nanshibukawa/disease-classification.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"nanshibukawa\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"3ff52196ea8c6fbefe8162ac963e4fa611ecc27c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50639ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 20:01:22.350709: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-09 20:01:22.358808: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-09 20:01:22.368240: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-09 20:01:22.371428: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-09 20:01:22.378458: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-09 20:01:22.853634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8055a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752102083.763346   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.800661   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.802885   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.807016   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.809407   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.811541   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.892381   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.893424   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1752102083.894400   28529 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-07-09 20:01:23.895274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6117 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"artifacts/training/model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43108c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b482242",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants.constants import *\n",
    "\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f9f7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants.constants import CONFIG_FILE_PATH, PARAMS_FILE_PATH\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model = \"artifacts/training/model.keras\",\n",
    "            training_data = \"artifacts/data_ingestion/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone/CT-KIDNEY-DATASET-Normal-Cyst-Tumor-Stone\",\n",
    "            mlflow_uri = \"https://dagshub.com/nanshibukawa/disease-classification.mlflow\",\n",
    "            all_params = self.params,\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_batch_size = self.params.BATCH_SIZE\n",
    "        )\n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb72f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanshibukawa/Documents/mestrado/disease-classification/.venv/lib/python3.11/site-packages/mlflow/utils/requirements_utils.py:12: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22ef7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def _create_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale=1.0 / 255.0,\n",
    "            validation_split=0.3\n",
    "        )\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "            )\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "        self._valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> tf.keras.Model:\n",
    "        return tf.keras.models.load_model(path)\n",
    "    \n",
    "    def evaluation(self):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        self._create_valid_generator()\n",
    "        self.score = self.model.evaluate(self._valid_generator)\n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\n",
    "            \"loss\": self.score[0],\n",
    "            \"accuracy\": self.score[1],\n",
    "        }\n",
    "        save_json(\n",
    "            path = Path(\"scores.json\"),\n",
    "            data=scores\n",
    "        )\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics({\n",
    "                \"loss\": self.score[0],\n",
    "                \"accuracy\": self.score[1],\n",
    "            })\n",
    "\n",
    "\n",
    "            # --- NEW APPROACH FOR LOGGING MODEL ---\n",
    "            # 1. Define a temporary path to save the model locally before logging\n",
    "            # local_model_path = Path(\"local_model_to_log.keras\")\n",
    "            local_model_path = Path(\"VGG16Model.keras\")\n",
    "            # 2. Save the model directly using Keras's save method\n",
    "            # This is where you specify the .keras extension explicitly\n",
    "            # and avoid the deprecated 'save_format' argument.\n",
    "            self.model.save(local_model_path)\n",
    "            print(f\"Model temporarily saved to: {local_model_path}\")\n",
    "\n",
    "            # 3. Log the saved model file as an artifact\n",
    "            # You can still give it a name within MLflow artifacts (e.g., \"model.keras\")\n",
    "            mlflow.log_artifact(str(local_model_path), artifact_path=\"model.keras\")\n",
    "\n",
    "            # 4. If you want to REGISTER the model, use mlflow.register_model\n",
    "            # This points to the artifact you just logged.\n",
    "            # Make sure you have the full artifact URI.\n",
    "            # You might need to construct this based on your run_id\n",
    "            # For simplicity, for now, we'll just log the artifact.\n",
    "            # If you specifically need model registration, it's a bit more involved\n",
    "            # to get the correct URI.\n",
    "            # A common pattern is:\n",
    "            logged_model_uri = f\"runs:/{mlflow.active_run().info.run_id}/model.keras\"\n",
    "            mlflow.register_model(logged_model_uri, \"VGG16Model\")\n",
    "            # --- END NEW APPROACH ---\n",
    "\n",
    "            # Remove the previous mlflow.keras.log_model calls\n",
    "            # if tracking_url_type_store != \"file\":\n",
    "            #     mlflow.keras.log_model(\n",
    "            #         self.model,\n",
    "            #         \"model.keras\",\n",
    "            #         registered_model_name=\"VGG16Model\",\n",
    "            #         keras_model_kwargs={\"save_format\": \"keras\"} # THIS IS NOW THE PROBLEM\n",
    "            #     )\n",
    "            # else:\n",
    "            #     mlflow.keras.log_model(\n",
    "            #         self.model,\n",
    "            #         \"model.keras\",\n",
    "            #         keras_model_kwargs={\"save_format\": \"keras\"} # THIS IS NOW THE PROBLEM\n",
    "            #     )\n",
    "\n",
    "            # Clean up the local temporary file\n",
    "            if local_model_path.exists():\n",
    "                os.remove(local_model_path)\n",
    "                print(f\"Cleaned up local model file: {local_model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "            # if tracking_url_type_store != \"file\":\n",
    "            #     mlflow.keras.log_model(\n",
    "            #         self.model,\n",
    "            #         \"model.keras\", # This is the artifact path within MLflow\n",
    "            #         registered_model_name=\"VGG16Model\",\n",
    "            #         # ADD THIS ARGUMENT:\n",
    "            #         keras_model_kwargs={\"save_format\": \"keras\"}\n",
    "            #     )\n",
    "            #     # mlflow.keras.log_model(self.model, \"model.keras\", registered_model_name=\"VGG16Model\")\n",
    "\n",
    "            # else:\n",
    "            #     mlflow.keras.log_model(self.model, \"model.keras\"\n",
    "            #         # self.model,\n",
    "            #         # \"model.keras\"\n",
    "            #     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b031a499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-07-09 20:01:24\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33mread_yaml\u001b[0m:\u001b[36m35\u001b[0m | \u001b[1mYAML file read successfully from config/config.yaml\u001b[0m\n",
      "\u001b[32m2025-07-09 20:01:24\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33mread_yaml\u001b[0m:\u001b[36m47\u001b[0m | \u001b[1mYAML file content: {'artifacts_root': 'artifacts', 'data_ingestion': {'root_dir': 'artifacts/data_ingestion', 'source_URL': 'https://drive.google.com/file/d/1oT2VFbMnAScIhUcPpP1q0zjcWZtlSSv4/view?usp=sharing', 'source_URL_id': '1oT2VFbMnAScIhUcPpP1q0zjcWZtlSSv4', 'local_data_file': 'artifacts/data_ingestion/data.zip', 'unzip_dir': 'artifacts/data_ingestion'}, 'prepare_base_model': {'root_dir': 'artifacts/prepare_base_model', 'base_model_path': 'artifacts/prepare_base_model/base_model.h5', 'updated_base_model_path': 'artifacts/prepare_base_model/base_model_updated.h5'}, 'training': {'root_dir': 'artifacts/training', 'trained_model_path': 'artifacts/training/model.keras'}}\u001b[0m\n",
      "\u001b[32m2025-07-09 20:01:24\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33mread_yaml\u001b[0m:\u001b[36m35\u001b[0m | \u001b[1mYAML file read successfully from params.yaml\u001b[0m\n",
      "\u001b[32m2025-07-09 20:01:24\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33mread_yaml\u001b[0m:\u001b[36m47\u001b[0m | \u001b[1mYAML file content: {'AUGMENTATION': True, 'IMAGE_SIZE': [224, 224, 3], 'BATCH_SIZE': 16, 'INCLUDE_TOP': False, 'EPOCHS': 10, 'CLASSES': 4, 'WEIGHTS': 'imagenet', 'LEARNING_RATE': 0.08}\u001b[0m\n",
      "\u001b[32m2025-07-09 20:01:24\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33mcreate_directories\u001b[0m:\u001b[36m68\u001b[0m | \u001b[1mCreated directory: artifacts\u001b[0m\n",
      "Found 3732 images belonging to 4 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nanshibukawa/Documents/mestrado/disease-classification/.venv/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1752102085.278026   28624 service.cc:146] XLA service 0x75d068016620 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1752102085.278058   28624 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2025-07-09 20:01:25.289568: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-09 20:01:25.344229: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  3/234\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.4826 - loss: 5.3536"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1752102091.348198   28624 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m234/234\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 54ms/step - accuracy: 0.4400 - loss: 42.9521\n",
      "\u001b[32m2025-07-09 20:01:43\u001b[0m | \u001b[1m\u001b[1mINFO    \u001b[0m\u001b[1m\u001b[0m | \u001b[34mcnnClassifier.utils.common\u001b[0m:\u001b[33msave_json\u001b[0m:\u001b[36m81\u001b[0m | \u001b[1mJSON file saved at scores.json\u001b[0m\n",
      "Model temporarily saved to: VGG16Model.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2025/07/09 20:01:56 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 7\n",
      "Created version '7' of model 'VGG16Model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up local model file: VGG16Model.keras\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "try:\n",
    "\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c90df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  9 20:01:57 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.133.07             Driver Version: 570.133.07     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   52C    P0             19W /   80W |    6304MiB /   8188MiB |      6%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A           15429      G   /usr/lib/xorg/Xorg                       53MiB |\n",
      "|    0   N/A  N/A           28529      C   ...assification/.venv/bin/python       6232MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel deu pane ao executar o código na célula atual ou em uma célula anterior. \n",
      "\u001b[1;31mAnalise o código nas células para identificar uma possível causa da pane. \n",
      "\u001b[1;31mClique <a href='https://aka.ms/vscodeJupyterKernelCrash'>aqui</a> para obter mais informações. \n",
      "\u001b[1;31mConsulte Jupyter <a href='command:jupyter.viewOutput'>log</a> para obter mais detalhes."
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disease-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
